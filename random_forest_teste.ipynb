{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "gsK4CI2CoNac",
    "outputId": "ef564ce2-99ba-418d-adbe-44fa72dd4301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando no Dataset 1\n",
      "Acurácias: [0.5 0.6 0.7 0.5 0.9]\n",
      "Média da Acurácia: 0.6400\n",
      "\n",
      "Treinando no Dataset 2\n",
      "Acurácias: [0.8 0.8 0.7 0.7 0.6]\n",
      "Média da Acurácia: 0.7200\n",
      "\n",
      "Treinando no Dataset 3\n",
      "Acurácias: [0.64285714 0.88095238 0.95238095 0.92857143 0.90243902]\n",
      "Média da Acurácia: 0.8614\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"poker-matches-dataset.csv\")\n",
    "data = pd.read_csv('games.csv')\n",
    "data_2 = pd.read_csv('games_2.csv')\n",
    "\n",
    "\n",
    "X = data[['Score']]\n",
    "y = data['Resultado']\n",
    "\n",
    "X_2 = data_2[['Score', 'Apostadores', 'Desistentes']]\n",
    "y_2 = data_2['Resultado']\n",
    "\n",
    "X_3 = df.drop(columns=['Continuar'])  \n",
    "y_3 = df['Continuar']      \n",
    "\n",
    "k = 5\n",
    "\n",
    "datasets = [\n",
    "    (X, y),\n",
    "    (X_2, y_2),\n",
    "    (X_3, y_3)\n",
    "]\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "results = []\n",
    "feature_importances = []\n",
    "\n",
    "for i, (X, y) in enumerate(datasets):\n",
    "    print(f\"\\nTreinando no Dataset {i + 1}\")\n",
    "    scores = cross_val_score(rf_model, X, y, cv=k, scoring='accuracy')\n",
    "    results.append(scores)\n",
    "\n",
    "    rf_model.fit(X, y)\n",
    "    feature_importances.append(rf_model.feature_importances_)\n",
    "\n",
    "    print(f\"Acurácias: {scores}\")\n",
    "    print(f\"Média da Acurácia: {np.mean(scores):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teste de Friedman:\n",
      "Estatística: 6.0000000000000036\n",
      "p-valor: 0.04978706836786384\n",
      "Há diferenças estatisticamente significativas entre os datasets.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# Executar o Teste de Friedman para comparar as acurácias\n",
    "friedman_stat, friedman_p = friedmanchisquare(*results)\n",
    "print(\"\\nTeste de Friedman:\")\n",
    "print(\"Estatística:\", friedman_stat)\n",
    "print(\"p-valor:\", friedman_p)\n",
    "\n",
    "if friedman_p < 0.05:\n",
    "    print(\"Há diferenças estatisticamente significativas entre os datasets.\")\n",
    "else:\n",
    "    print(\"Não há diferenças estatisticamente significativas entre os datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman Test Statistic: 6.0000, p-value: 0.0498\n",
      "Diferenças estatisticamente significativas detectadas! Realizando análise pós-hoc.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'Orange.evaluation.scoring' has no attribute 'compute_CD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m dataset_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mean_ranks))]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Diagrama de Diferença Crítica com Orange\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m cd \u001b[38;5;241m=\u001b[39m \u001b[43mscoring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_CD\u001b[49m(mean_ranks, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;241m0\u001b[39m]), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.05\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# CD para teste de Nemenyi\u001b[39;00m\n\u001b[0;32m     31\u001b[0m scoring\u001b[38;5;241m.\u001b[39mgraph_ranks(mean_ranks, dataset_names, cd\u001b[38;5;241m=\u001b[39mcd, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m     32\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'Orange.evaluation.scoring' has no attribute 'compute_CD'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import friedmanchisquare, rankdata\n",
    "import importlib\n",
    "from Orange.evaluation import scoring\n",
    "_ = importlib.reload( scoring )\n",
    "\n",
    "# Simulação de dados para teste (substitua pelo seu array `results`)\n",
    "# results = np.array([[0.8, 0.85, 0.82], [0.78, 0.81, 0.79], [0.76, 0.80, 0.78]])\n",
    "results = np.array(results)\n",
    "\n",
    "# Verifica o formato correto: (n_datasets, n_folds)\n",
    "assert results.shape[1] > results.shape[0], \"Os dados devem ter formato (n_datasets, n_folds).\"\n",
    "\n",
    "# Teste de Friedman\n",
    "friedman_stat, friedman_p = friedmanchisquare(*results)  # Transpõe para formato adequado\n",
    "print(f\"Friedman Test Statistic: {friedman_stat:.4f}, p-value: {friedman_p:.4f}\")\n",
    "\n",
    "if friedman_p < 0.05:\n",
    "    print(\"Diferenças estatisticamente significativas detectadas! Realizando análise pós-hoc.\")\n",
    "\n",
    "    # Cálculo das ranks médias\n",
    "    ranks = np.array([rankdata(-fold) for fold in results])  # Rank por fold\n",
    "    mean_ranks = np.mean(ranks, axis=0)\n",
    "\n",
    "    # Nomes dos datasets\n",
    "    dataset_names = [f\"Dataset {i+1}\" for i in range(len(mean_ranks))]\n",
    "\n",
    "    # Diagrama de Diferença Crítica com Orange\n",
    "    cd = scoring.compute_CD(mean_ranks, n=len(results[0]), alpha=\"0.05\")  # CD para teste de Nemenyi\n",
    "    scoring.graph_ranks(mean_ranks, dataset_names, cd=cd, width=6)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Nenhuma diferença estatisticamente significativa detectada. Não será gerado o diagrama.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base 1\n",
      "\n",
      "Acurácias por fold: [0.5 0.6 0.7 0.5 0.9]\n",
      "Acurácia média: 0.64\n",
      "\n",
      "Base 2\n",
      "\n",
      "Acurácias por fold: [0.8 0.8 0.7 0.7 0.6]\n",
      "Acurácia média: 0.72\n",
      "\n",
      "Base 3\n",
      "\n",
      "Acurácias por fold: [0.64285714 0.88095238 0.95238095 0.92857143 0.90243902]\n",
      "Acurácia média: 0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBase 1\")\n",
    "print(f'\\nAcurácias por fold: {k_fold}')\n",
    "print(f'Acurácia média: {k_fold.mean():.2f}')\n",
    "print(\"\\nBase 2\")\n",
    "print(f'\\nAcurácias por fold: {k_fold_2}')\n",
    "print(f'Acurácia média: {k_fold_2.mean():.2f}')\n",
    "print(\"\\nBase 3\")\n",
    "print(f'\\nAcurácias por fold: {k_fold_3}')\n",
    "print(f'Acurácia média: {k_fold_3.mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNUVyoW_rOPg",
    "outputId": "b0dc1db8-e366-4ebf-bc5e-3e6fbb8c6225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Base 1 =========\n",
      "Score: 0.15\n",
      "\n",
      "========= Base 2 =========\n",
      "Score: 0.15\n",
      "Apostadores: 0.09\n",
      "Desistentes: 0.23\n",
      "\n",
      "========= Base 3 =========\n",
      "Score: 0.15\n",
      "Perfil: 0.09\n",
      "Aposta Necessaria: 0.23\n",
      "Jackpot: 0.27\n",
      "Jogadores Restantes: 0.08\n",
      "Desistentes: 0.18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n========= Base 1 =========\")\n",
    "importances = decision_model_3.feature_importances_\n",
    "for feature, importance in zip(X.columns, importances):\n",
    "    print(f'{feature}: {importance:.2f}')\n",
    "\n",
    "print(\"\\n========= Base 2 =========\")\n",
    "importances = decision_model_3.feature_importances_\n",
    "for feature, importance in zip(X_2.columns, importances):\n",
    "    print(f'{feature}: {importance:.2f}')\n",
    "\n",
    "print(\"\\n========= Base 3 =========\")\n",
    "importances = decision_model_3.feature_importances_\n",
    "for feature, importance in zip(X_3.columns, importances):\n",
    "    print(f'{feature}: {importance:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "#dump(decision_model_3, \"modelos/random_forest_model83%.joblib\")\n",
    "#print(\"Modelo salvo com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
